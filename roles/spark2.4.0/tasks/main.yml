---
- name: "create remote dir {{spark.remote_dir}}"
  file: path={{spark.remote_dir}} state=directory

- name: "create install dir {{spark.install_dir}}"
  file: path={{spark.install_dir}} state=directory

- name: "Create spark data directory."
  file: path={{item}} state=directory
  with_items:
    - "{{spark.pid_dir}}"
    - "{{spark.log_dir}}"
    - "{{spark.work_dir}}"

- name: copy {{spark.filename}} to remote host {{spark.remote_dir}}
  copy: src={{spark.filename}} dest={{spark.remote_dir}}

- name: "unzip install package {{spark.filename}} to {{spark.install_dir}}"
  unarchive: 
    src: "{{spark.remote_dir}}/{{spark.filename}}"
    dest: "{{spark.install_dir}}"
    copy: no
    extra_opts:
     - --strip-components=1

- name: set spark env {{spark.env_file}}
  tags: env
  lineinfile: dest={{spark.env_file}} insertafter="{{item.position}}" line="{{item.value}}" state=present
  with_items:
    - {position: EOF, value: "#########SPARK ENV########"}
    - {position: EOF, value: "export SPARK_HOME={{spark.install_dir}}"}
    - {position: EOF, value: "export PATH=$SPARK_HOME/bin:$PATH"}

- name: enable spark env {{spark.env_file}}
  tags: env
  shell: "source {{spark.env_file}}"

- name: create hdfs log dir {{spark.history_log}}
  shell: "{{HADOOP_HOME}}/bin/hdfs dfs -mkdir -p {{spark.history_log}}"
  when: spark_active == "true"

- name: create hdfs log dir {{spark.event_log}}
  shell: "{{HADOOP_HOME}}/bin/hdfs dfs -mkdir -p {{spark.event_log}}"
  when: spark_active == "true"

- name: create hdfs yarn archive dir {{spark.yarn_archive}}
  shell: "{{HADOOP_HOME}}/bin/hdfs dfs -mkdir -p {{spark.yarn_archive}}"
  when: spark_active == "true"

- name: upload jars to hdfs {{spark.yarn_archive}}
  shell: "{{HADOOP_HOME}}/bin/hdfs dfs -put {{SPARK_HOME}}/jars/* {{spark.yarn_archive}}"
  when: spark_active == "true"

- name: Write spark-env.sh file
  template: src=spark-env.sh.j2 dest={{spark.install_dir}}/conf/spark-env.sh

- name: Write slaves file
  template: src=slaves.j2 dest={{spark.install_dir}}/conf/slaves

- name: Write spark-defaults.conf file
  template: src=spark-defaults.conf.j2 dest={{spark.install_dir}}/conf/spark-defaults.conf

- name: start active on spark_active
  shell: "{{spark.install_dir}}/sbin/start-all.sh"
  when: spark_active == "true"

- name: start standby on spark_tandby
  shell: "{{spark.install_dir}}/sbin/start-master.sh"
  when: spark_standby == "true"

- name: start spark history server on spark_tandby
  shell: "{{spark.install_dir}}/sbin/start-history-server.sh"
  when: spark_standby == "true"

